import numpy as np

sigmoid = lambda x: 1 / (1 + np.exp(-x))
sigmoid_derivative = lambda x: x * (1 - x)

# XOR data
X, y = np.array([[0, 0], [0, 1], [1, 0], [1, 1]]), np.array([[0], [1], [1], [0]])

# Initialization
np.random.seed(42)
input_layer_neurons, hidden_layer_neurons, output_neurons = 2, 4, 1
weights_input_hidden = np.random.uniform(size=(input_layer_neurons, hidden_layer_neurons))
weights_hidden_output = np.random.uniform(size=(hidden_layer_neurons, output_neurons))
bias_hidden, bias_output = np.random.uniform(size=(1, hidden_layer_neurons)), np.random.uniform(size=(1, output_neurons))

# Training loop
for _ in range(10000):
    hidden_output = sigmoid(np.dot(X, weights_input_hidden) + bias_hidden)
    output = sigmoid(np.dot(hidden_output, weights_hidden_output) + bias_output)
    error = y - output
    d_output = error * sigmoid_derivative(output)
    d_hidden = d_output.dot(weights_hidden_output.T) * sigmoid_derivative(hidden_output)

    # Update weights and biases
    weights_hidden_output += hidden_output.T.dot(d_output) * 0.5
    bias_output += np.sum(d_output, axis=0, keepdims=True) * 0.5
    weights_input_hidden += X.T.dot(d_hidden) * 0.5
    bias_hidden += np.sum(d_hidden, axis=0, keepdims=True) * 0.5

# Output results
print("Trained Output:\n", output)
print("\nTesting the ANN:")
for test_input in X:
    pred = sigmoid(np.dot(sigmoid(np.dot(test_input, weights_input_hidden) + bias_hidden), weights_hidden_output) + bias_output)
    print(f"Input: {test_input}, Predicted Output: {pred}")
